{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4w56jiTzCCSA"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "import string\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3WcE7Jfhdrz9"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\I059953\\Desktop\\Hate speech\\Hate speech\\labeled_data.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8dtgqRDF95w4"
   },
   "outputs": [],
   "source": [
    "all_sentences = []\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "  tweet = \"\"\n",
    "  s = df.iloc[i]['tweet']\n",
    "  # lowercase\n",
    "  s = s.lower()\n",
    "  # remove urls\n",
    "  s = re.sub(r'https?:\\/\\/\\S+', ' ', s)\n",
    "  s = re.sub(r\"www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)\", ' ', s)\n",
    "  # change @... and #abc to thisisatag\n",
    "  s = re.sub(r'\\s([@#][\\w_-]+)', ' thisisatag ', s)\n",
    "  # remove non-letter chars\n",
    "  s = re.sub(r\"[^a-z\\s\\(\\-:\\)\\\\\\/\\];='#]\", ' ', s)\n",
    "  # thisisatag -> TAG\n",
    "  s = re.sub(r\" thisisatag \", ' TAG ', s)\n",
    "  # remove rt\n",
    "  s = re.sub(r\" rt \", ' ', s)\n",
    "  # remove unecessary spacing\n",
    "  s = s.strip()\n",
    "  s = tweet_tokenizer.tokenize(s)\n",
    "  # remove punctuation after tokenization\n",
    "  for j in s:\n",
    "    if j not in string.punctuation:\n",
    "      tweet = tweet + j + \" \"\n",
    "  all_sentences.append(tweet[:-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4SWAiOIfoEce"
   },
   "outputs": [],
   "source": [
    "clean_text_df = pd.DataFrame(columns=['tweet', 'label'])\n",
    "for i in range(len(all_sentences)):\n",
    "  # add tweet and label to clean_df\n",
    "  tweet = all_sentences[i]\n",
    "  label = df.iloc[i]['class']\n",
    "  # is hate speech\n",
    "  if label == 0:\n",
    "    label = 1\n",
    "  # not hate speech \n",
    "  else:\n",
    "    label = 0\n",
    "  clean_text_df.loc[i] = [tweet, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6pJrw_DmFf86"
   },
   "outputs": [],
   "source": [
    "myTokenizer = Tokenizer()\n",
    "myTokenizer.fit_on_texts(all_sentences)\n",
    "token_sequences = myTokenizer.texts_to_sequences(all_sentences)\n",
    "padded_sequences = pad_sequences(token_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "og7Qw5PVF9nM"
   },
   "outputs": [],
   "source": [
    "clean_df = pd.DataFrame(columns=['tweet', 'label'])\n",
    "for i in range(len(padded_sequences)):\n",
    "  # add tweet and label to clean_df\n",
    "  clean_df.loc[i] = [padded_sequences[i].tolist(), df.iloc[i]['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "UbwTfg9Ochj-",
    "HAKp-EyYdrrv"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
